% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/twitSmany2json.R
\name{twitSmany2json}
\alias{twitSmany2json}
\title{Write many Twitter search requests to JSON file}
\usage{
twitSmany2json(filename, twitter_token, n = 5000, my_oauth = NULL, q = "",
  geocode = NULL, lang = NULL, result_type = NULL, until = NULL,
  since_id = NULL, max_id = NULL, verbose = TRUE, append_old = FALSE)
}
\arguments{
\item{filename}{Character. File path to json file to store data.}

\item{twitter_token}{Your twitter_token; e.g. from twitToken() function.}

\item{n}{(optional) Integer. Maximum total tweets to pull from the timeline.}

\item{verbose}{(defaults TRUE) Logical. If true, displays request limit at each request.}

\item{append_old}{(defaults FALSE) Logical. If true will append an already extant json file; otherwise it creates/overwrites file.}

\item{q='', }{geocode, lang, result_type, until, since_id, max_id 
To set up query. See ?twitSQuery for details}
}
\description{
Used to extract many repeated requests to pull searchs and save the results to a json file.
Will automatically move from most recent toward older tweets while pulling data.
}
\examples{
twitter_token <- twitToken(consumer_key, consumer_secret, access_token, access_secret)
twitSmany2json(filename='~/thomas_laetsch.json', twitter_token = twitter_token, q = 'thomas laetsch uconn OR nyu')
}

